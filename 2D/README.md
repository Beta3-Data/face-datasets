
http://www.face-rec.org/databases/

## 2D (incomplete - WIP)

#### WIDER FACE
http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/index.html

#### NIST-provided (IJB-B + FRVT (testing only))
The IARPA Janus Benchmark-B face challenge (IJB-B) defines eight challenges addressing verification, identification, detection, clustering and processing of crowded images.  This is supported by a the IJB-B set of 67000 face images, 7000 face videos, and 10000 non-face images.

https://www.nist.gov/programs-projects/face-challenges

#### AFW
http://www.ics.uci.edu/~xzhu/face/

#### 300-W (LFPW + AFW + HELEN + IBUG)
https://ibug.doc.ic.ac.uk/resources/300-W/

#### MALF
http://www.cbsr.ia.ac.cn/faceevaluation/

#### FDDB (2009/10)
A data set of face regions designed for studying the problem of unconstrained face detection. This data set contains the annotations for 5171 faces in a set of 2845 images taken from the Faces in the Wild data set. More details can be found in the technical report below.
http://vis-www.cs.umass.edu/fddb/index.html

#### VGGFace
http://www.robots.ox.ac.uk/~vgg/data/vgg_face/

#### VGGFace2
The dataset contains 3.31 million images of 9131 subjects (identities), with an average of 362.6 images for each subject. Images are downloaded from Google Image Search and have large variations in pose, age, illumination, ethnicity and profession (e.g. actors, athletes, politicians).The dataset was collected with three goals in mind:
(i) to have both a large number of identities and also a large number of images for each identity;
(ii) to cover a large range of pose, age and ethnicity; and
(iii) to minimize the label noise through automated and manual filtering,
The whole dataset is split to a training set (including 8631 identites) and a test set (including 500 identites). The identities in the training set are disjoint with the ones in benchmark datasets IJB-A and IJB-B. 
http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/
(paper - https://arxiv.org/abs/1710.08092)

#### Multi-PIE

A close relationship exists between the advancement of face recognition algorithms and the availability of face databases varying factors that affect facial appearance in a controlled manner. The PIE database, collected at Carnegie Mellon University in 2000, has been very influential in advancing research in face recognition across pose and illumination. Despite its success the PIE database has several shortcomings: a limited number of subjects, a single recording session and only few expressions captured.

To address these issues researchers at Carnegie Mellon University collected the Multi-PIE database. It contains 337 subjects, captured under 15 view points and 19 illumination conditions in four recording sessions for a total of more than 750,000 images.

Labels are provided for a total of 6152 images of Multi-PIE. Illumination images were captured by recording 20 images within 0.7 seconds with flashes firing one by one. Due to the minimal subject movement between the different flash images the labels could be copied across all illumination conditions. These are AAM-style labels with between 39 and 68 feature points depending on the pose which were determined manually. Here is an illustration for the points labeled for the frontal view.

https://www.flintbox.com/public/project/4742/
